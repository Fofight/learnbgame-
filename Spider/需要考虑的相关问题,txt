大规模爬虫被网站封禁的问题

保存文件重名覆盖的问题

长时间无人值守网络不稳定的问题

保存为本地txt时名称出错的问题

多线程抓取以及无图版抓取 网页抓取速度的一些问题


理论上，大规模的爬虫可以采用多线程的方法加快抓取速度，但是考虑到不要对网站造成过大的压力，也为避免被网站封禁IP，所以主程序中未引入多线程的概念。但是又为了加快进度，就手动打开多个命令行窗口运行爬虫，来同时抓取不同的版面的文章。这样，当一个程序报错，其他的仍然能运行，也是增强了程序的容错性。




